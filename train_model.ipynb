{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e342d76-853f-4f76-9143-59026597c6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: keras in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: rich in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from keras) (0.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vyshn\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy nltk scikit-learn tensorflow keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68f13e2-c9a1-43e4-8e73-a50cd3e8d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0  Go until jurong point, crazy.. Available only ...\n",
      "1      0                      Ok lar... Joking wif u oni...\n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      0  U dun say so early hor... U c already then say...\n",
      "4      0  Nah I don't think he goes to usf, he lives aro...\n",
      "label\n",
      "0    4825\n",
      "1     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")[['v1', 'v2']]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Convert labels to binary (spam = 1, ham = 0)\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Display data\n",
    "print(df.head())\n",
    "print(df['label'].value_counts())  # Check class distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aa8171c-24ff-4947-879a-9f450edb84d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vyshn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text  \\\n",
      "0      0  Go until jurong point, crazy.. Available only ...   \n",
      "1      0                      Ok lar... Joking wif u oni...   \n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3      0  U dun say so early hor... U c already then say...   \n",
      "4      0  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                           clean_tex  \\\n",
      "0  go jurong point crazi avail bugi n great world...   \n",
      "1                              ok lar joke wif u oni   \n",
      "2  free entri wkli comp win fa cup final tkt st m...   \n",
      "3                u dun say earli hor u c alreadi say   \n",
      "4          nah dont think goe usf live around though   \n",
      "\n",
      "                                          clean_text  \n",
      "0  go jurong point crazi avail bugi n great world...  \n",
      "1                              ok lar joke wif u oni  \n",
      "2  free entri wkli comp win fa cup final tkt st m...  \n",
      "3                u dun say earli hor u c alreadi say  \n",
      "4          nah dont think goe usf live around though  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    words = text.split()\n",
    "    words = [stemmer.stem(word) for word in words if word not in stop_words]  # Remove stopwords & stem\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"clean_text\"] = df['text'].apply(clean_text)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b79be70-49d2-4cb6-961d-31145d55ea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Shape: (5572, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert text data to TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df[\"clean_text\"]).toarray()\n",
    "y = df[\"label\"]\n",
    "\n",
    "print(\"TF-IDF Shape:\", X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc42a457-56c9-4800-8074-86c0b6771251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.9713004484304932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       965\n",
      "           1       1.00      0.79      0.88       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Naïve Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e780fdc-4f90-4aa2-bb93-f6802efd0248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9775784753363229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       965\n",
      "           1       1.00      0.83      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da80f16a-9bad-4204-a8cb-d53021809d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['clean_text'])\n",
    "X_nn = tokenizer.texts_to_sequences(df['clean_text'])\n",
    "\n",
    "# Padding sequences\n",
    "X_nn = pad_sequences(X_nn, maxlen=100)\n",
    "\n",
    "# Split dataset\n",
    "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_nn, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "226b6c9a-e601-4a9f-aa17-0d9e8018feef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vyshn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 176ms/step - accuracy: 0.8948 - loss: 0.3019 - val_accuracy: 0.9821 - val_loss: 0.0620\n",
      "Epoch 2/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 164ms/step - accuracy: 0.9873 - loss: 0.0444 - val_accuracy: 0.9865 - val_loss: 0.0518\n",
      "Epoch 3/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 166ms/step - accuracy: 0.9956 - loss: 0.0169 - val_accuracy: 0.9857 - val_loss: 0.0575\n",
      "Epoch 4/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 161ms/step - accuracy: 0.9992 - loss: 0.0059 - val_accuracy: 0.9830 - val_loss: 0.0669\n",
      "Epoch 5/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 158ms/step - accuracy: 0.9995 - loss: 0.0035 - val_accuracy: 0.9758 - val_loss: 0.0785\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9783 - loss: 0.0618\n",
      "LSTM Accuracy: 0.9757847785949707\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Define LSTM model\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "lstm_model.fit(X_train_nn, y_train_nn, epochs=5, batch_size=32, validation_data=(X_test_nn, y_test_nn))\n",
    "\n",
    "# Evaluate LSTM\n",
    "_, lstm_acc = lstm_model.evaluate(X_test_nn, y_test_nn)\n",
    "print(\"LSTM Accuracy:\", lstm_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "866bbbea-61e8-4b59-9fb5-4c1cb8dd1cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 178ms/step - accuracy: 0.8859 - loss: 0.3256 - val_accuracy: 0.9857 - val_loss: 0.0626\n",
      "Epoch 2/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 166ms/step - accuracy: 0.9891 - loss: 0.0444 - val_accuracy: 0.9839 - val_loss: 0.0588\n",
      "Epoch 3/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 155ms/step - accuracy: 0.9984 - loss: 0.0085 - val_accuracy: 0.9839 - val_loss: 0.0622\n",
      "Epoch 4/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 159ms/step - accuracy: 0.9982 - loss: 0.0112 - val_accuracy: 0.9830 - val_loss: 0.0756\n",
      "Epoch 5/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 151ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9839 - val_loss: 0.0864\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9875 - loss: 0.0585\n",
      "GRU Accuracy: 0.9838564991950989\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "# Define GRU model\n",
    "gru_model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    GRU(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "gru_model.fit(X_train_nn, y_train_nn, epochs=5, batch_size=32, validation_data=(X_test_nn, y_test_nn))\n",
    "\n",
    "# Evaluate GRU\n",
    "_, gru_acc = gru_model.evaluate(X_test_nn, y_test_nn)\n",
    "print(\"GRU Accuracy:\", gru_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3c97aa1-f40c-4d3a-a193-c48f64f316c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.9713004484304932\n",
      "Random Forest Accuracy: 0.9775784753363229\n",
      "LSTM Accuracy: 0.9757847785949707\n",
      "GRU Accuracy: 0.9838564991950989\n"
     ]
    }
   ],
   "source": [
    "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"LSTM Accuracy:\", lstm_acc)\n",
    "print(\"GRU Accuracy:\", gru_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ea0e956-7b92-4485-9411-f28c53181eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model (use Naïve Bayes or any best-performing model)\n",
    "with open(\"spam_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(nb_model, model_file)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
